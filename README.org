#+title: README
* Overview
This project demonstrates an [[https://nasa.github.io/fprime/][fprime]] powered flight software deployment which leverages state machines and other MBSE type models to generate code.

** Getting Started
*** Dependencies
The project is containerized with Docker, ensuring compatibility across various environments including Ubuntu and WSL (Windows Subsystem for Linux). Before proceeding, ensure you have the following dependencies installed:

- [[https://git-scm.com/book/en/v2/Getting-Started-Installing-Git][Git]] (For cloning the repository)
- [[https://docs.docker.com/engine/install/][Docker]] (For running the software)

[[https://docs.docker.com/engine/install/linux-postinstall/][Ensure Docker is configured to run without ~sudo~ in your environment]]
*** Setting up the repo
**** Clone the repo and submodules
#+BEGIN_SRC bash
#Get the repo
git clone git@github.com:ReggieMarr/space-vehicle-system.git
cd space-vehicle-system
#pull in the submodules
git submodule update --init --recursive
#+END_SRC

** Example Usage
The flight software ships with a script run.sh  which can be used to simplify development and interaction with this repo's assets.
Commands are summarized as such:

#+begin_src plantuml :file .org_out/run.png :tangle .org_out/run.puml :exports results
@startuml
skinparam actorStyle awesome
actor User
rectangle "Commands" {
  [Docker Build]
  [Project Build]
  [Container Inspection]
  [Execution Commands]
  note right of [Execution Commands]
    exec command with subcommands:
    - FlightComputer
    - gds
    - test
  end note
  [Environment Teardown]
  [Update]
  [Sync]
  [Topology Visualization]
}
cloud "Docker Environment" {
  [Docker Image]
  [FSW Container]
  [GDS Container]
}
database "Host File System" {
  folder "Project Files"
  folder "Build Artifacts"
}
User --> [Docker Build] : docker-build
User --> [Project Build] : build
User --> [Container Inspection] : inspect
User --> [Execution Commands] : exec
[Execution Commands] --> [FlightComputer Execution]
[Execution Commands] --> [GDS Execution]
[Execution Commands] --> [Test Execution]
User --> [Environment Teardown] : teardown
User --> [Update] : update
User --> [Sync] : sync
User --> [Topology Visualization] : topology

[Docker Build] --> [Docker Image] : Creates/Updates
[Project Build] --> [Build Artifacts] : Generates
[Container Inspection] --> [FSW Container] : Provides shell
[FlightComputer Execution] --> [FSW Container] : Runs FlightSoftware
[GDS Execution] --> [GDS Container] : Runs GDS
[Test Execution] --> [GDS Container] : Runs tests
[Environment Teardown] --> [Docker Environment] : Removes containers
[Update] --> [Docker Image] : Pulls latest images
[Sync] --> [Docker Image] : Pushes local changes
[Topology Visualization] --> [Project Files] : Generates topology diagram

note right of User
  Available flags:
  --daemon
  --debug
  --as-host
  --clean
  --host-thread-ctrl
  --help
end note
@enduml
#+end_src

#+RESULTS:
[[file:.org_out/run.png]]

The script supports a number of useful commands.
Tab completion is enabled by entering the following:
#+BEGIN_SRC bash
source .gen-run-complete.sh
#+END_SRC

#+BEGIN_SRC bash
❯ ./run.sh --help
Usage: run.sh [OPTIONS] COMMAND

Options:
  --daemon             Run as daemon
  --debug              Enable debug mode
  --as-host            Run as host
  --clean              Clean build
  --host-thread-ctl    Set thread control for running without sudo (this itself requires sudo)
  --help               Show this help message
Commands:
  update               Build the Docker image
  docker-build         Build the Docker image
  build                Build the project
  inspect [container]  Inspect a container
  exec gds             Run the GDS
  exec FlightComputer  Run the Flight Software
  exec test            Run integration tests against the Flight Software
  update               Pull latest Docker images
  teardown             Tear down the environment
  topology             Generate topology visualization
#+END_SRC

One use case is building and running the deployment, this can be done like so (note building clean is only necessary when making significant changes):
#+begin_src bash
❯ ./run.sh build --clean && ./run.sh exec FlightComputer
#+end_src

This then provides a web based ui that can be viewed by visiting http://127.0.0.1:5000/#Channels on your preferred web browser.

*Note* this example runs a standard version of ~fprime-gds~ and deploys it locally.
More information about the Web UI can be found [[https://nasa.github.io/fprime/UsersGuide/gds/gds-introduction.html][here]].
*** Additional Tips
   - Script uses environment variables from .env file in the same directory
   - Use ~--daemon~ flag to run processes in the background
   - Use ~--host-thread-ctl~ when building for non-sudo host execution thread control

   Note: Ensure proper permissions and Docker setup before running commands.

* Flight Sequence State Machine
The following state machine is fed as input to [[https://github.com/JPLOpenSource/STARS][STARS]] which then generates ~fpp~ and ~c++~ as output.

#+BEGIN_SRC plantuml :tangle ./FlightSoftware/FlightSequencer/FlightSM.plantuml :exports both :file .org_out/FlightSM.svg
@startuml

[*] --> IDLE:  /initFlightStatus()

state IDLE {
}

state IN_FLIGHT {
    [*] --> FIRING
    IN_FLIGHT:Entry: initFlightStatus()
    'FIXME consolidate this and the TBURN interval
    IN_FLIGHT:Internal: UPDATE_INTERVAL/updateFlightStatus()

    state FIRING {
        FIRING:Entry: engageThrust()
    }
    state GLIDING {
        GLIDING:Entry: disengageThrust()
        GLIDING:Internal: UPDATE_INTERVAL/updateFlightStatus(); checkLowAltReached()
    }
    'NOTE this should probably be replaced by an event
    'but we wanted to play with conditions here
    state tBurnCheck <<choice>>
    FIRING --> tBurnCheck: TBURN_CHECK_INTERVAL
    tBurnCheck --> GLIDING: [isTBurnReached()]

}

IDLE --> IN_FLIGHT: IGNITE
IN_FLIGHT --> IDLE: TERMINATE

@enduml
#+END_SRC

#+RESULTS:
[[file:.org_out/FlightSM.svg]]


* CCSDS support
CCSDS represents a family of protocols created with aim to standardize communications between space entities across the OSI communication layers.
The protocols are well defined (with [[https://public.ccsds.org/Publications/AllPubs.aspx][an extensive catalogue of spec docs]]) and can used in combination with, or independent of one another.

The driving factor here is the need to provide a robust communications pipeline which adheres to F' conventions, provides an interface that external users may easily utilize and is capable of providing a multiplexed stream of system data generated at varying rates, conditions and in a wide range of formats (most notably video data and telemetry).
Since this will be integrated within resource constrained systems we want to minimize the complexity and bandwidth utilization.
For this reason this pipeline's development mostly focuses on the data link layer implemented to be compatible with F' with less support for a highly flexible API.

** Requirements
The components implemented in order to support CCSDS is contained in what will referred to as the "Space Link Pipeline" (SLP).
The following high level requirements serve to illustrate the related development goals and driving factors:

+ The SLP shall receive and propogate the following data types:
  + Telemetry - Continuously generated data originating from sensor reading, process execution, or system state.
  + Events - Spontaneously generated notifications.
  + Commands - Spontaneously generated requests to induce desired behaviour.
  + Parameters - Spontaneously generated requests to alter the systems configuration.
  + Video - A unique form of telemetry containing image data.
+ The SLP shall distinguish between data streams of the previously mentioned data types.
+ The SLP shall support data stream multiplexing to optimize bandwidth utilization.
+ The SLP shall transfer data in such a way that accounts for data transmission which may be weak and/or unreliable (e.g. RF links).
+ The SLP shall support both bi-directional and uni-directional links.
+ The SLP shall support missions for which access to bi-directional vs uni-directional links is not constant.
+ The SLP shall transfer data in a manner that considers performance needs in the following order.
  1. Computational processing which does not meaningfully impact mission specific operations.
  2. Memory utilization which does not meaningfully impact mission specific operations.
  3. Maximize bitrate.
  4. Minimize latency.
+ The SLP shall provide an interface which external parties may comprehend, interact with and adapt to based on well defined documentation and specifications.
+ The SLP shall provide telemetry/event packetization to the YAMCS operations control software for the live display of system data.
+ The SLP shall provide video packetization for the live visual representation of the system during mission execution.
+ The SLP implementation components developed for F' inclusion shall be developed according to F' coding standards and contributor guidelines.

** Theory of Operation - TM Space Data Link
*** Services and Protocol Functions
The TM Space Data Link spec recommendations make reference to ~Services~ and ~Functions~.
Essentially the description of the ~Functions~ conveys the separation of concerns and the procedural construction and propagation of message buffers (referred to as transfer frames).

The following excerpt from CCSDS 132.0-B-3 2.3.2 illustrates this with more details found in the source.

[[file:.org_out/TMSpaceDataLink_ProtocolEntity_Sending_Functions.png]]

[[file:.org_out/TMSpaceDataLink_ProtocolEntity_Channel_Tree_Description.png]]

[[file:.org_out/TMSpaceDataLink_ProtocolEntity_Channel_Tree_Diagram.png]]

*** Sending Procedure Protocol
In an effort to describe how the functional components and services are leveraged to receive, encapsulate and propogate user data the following high level example is used with the following restrictions:

+ Propagation of F' telemetry channel which contains unpacketized telem data through the protocol entity functions generated at a single rate.
+ This sequence uses a single virtual, master, and physical channel to create the transfer frames without operational control or secondary header fields.
+ The VCA service is used instead of the VCP so the telem data is just placed into a data field with padding.
+ Virtual channels multiplexing is just handling the combination of frames one channel and placing them into a queue.
+ No Master Channel multiplexing is performed.
+ All frames generation calculates the CRC and inserts it into each transfer frames error control field.

+ **Telemetry Data Reception:**
  - Telemetry data, tied to various rate groups, is propagated to the `ProtocolEntity` via a `UserComIn_handler`.

+ **Service Processing and Virtual Channel Frame Generation:**
  - The `VirtualChannelSender` processes the telemetry data using registered services (e.g., VCP or VCA).
  - The `PacketProcessing_handler` segments and blocks the data as required (if the VCP service exists which it doesn't right now).
  - The `VirtualChannelGeneration_handler` constructs a Virtual Channel Transfer Frame:
    - Adds the Primary Header with fields like VCID and Frame Count but leaves Master channel frames aside.
    - Optionally includes the Frame Secondary Header (FSH) or Operational Control Field (OCF) if the related service exist (again for my example they don't right now).
    - This is all done by the required service: Virtual Channel Frame (VCF) service.

+ **Virtual Channel Multiplexing:**
  - The `MasterChannelSender` invokes the `VirtualChannelMultiplexing_handler` to combine Transfer Frames from multiple Virtual Channels (VCs) associated with the Master Channel.
  - Frames are multiplexed according to a predefined priority or scheduling scheme as identified in the management parameters.

+ **Master Channel Frame Generation:**
  - The `MasterChannelGeneration_handler` processes the multiplexed VC frames:
    - Sets the Master Channel Frame Count in the Primary Header.
    - Optionally includes the Frame Secondary Header (FSH) or Operational Control Field (OCF) if the related service exist (again for my example they don't right now).

+ **Master Channel Multiplexing:**
  - The `PhysicalChannelSender` invokes the `MasterChannelMultiplexing_handler` to combine Transfer Frames from multiple Master Channels (MCs) (if applicable).
  - Frames are ordered and queued for transmission.

+ **All Frames Generation:**
  - The `AllFramesGeneration_handler` finalizes the frames:
    - Adds Frame Error Control Field (FECF) for error detection if enabled.
    - Marks idle frames as needed when no data is available.

+ **Transmission:**
  - Completed frames are transmitted over the Physical Channel at a constant rate, ensuring compliance with protocol timing requirements.

The following sequence diagram illustrates the procedure like so:
#+BEGIN_SRC plantuml :tangle ./FlightSoftware/FlightSequencer/ccsds_tm_datalink_sequence.plantuml :exports both :file .org_out/ccsds_tm_datalink_sequence.svg
@startuml
participant "Protocol Entity" as ProtocolEntity
participant "Virtual Channel Handler" as VirtualChannelHandler
participant "Master Channel Handler" as MasterChannelHandler
participant "Physical Channel Handler" as PhysicalChannelHandler

' Telemetry Data Reception
ProtocolEntity -> ProtocolEntity : receiveTelemetryData(rawTelemetryData)
note right
Telemetry data tied to rate groups is received
and propagated to the Protocol Entity.
end note

' Virtual Channel Processing and Frame Generation
ProtocolEntity -> VirtualChannelHandler : processTelemetryData(serviceDataUnit)
note right
Processes telemetry data:
- In this example, VCA service is used.
- Telemetry data is placed into the data field with padding.
end note

VirtualChannelHandler -> VirtualChannelHandler : generateVirtualChannelFrame(serviceDataUnit)
note right
Creates a Virtual Channel Transfer Frame:
- Adds Primary Header with VCID, Frame Count.
- Leaves optional fields (FSH, OCF) out as not used.
end note

' Virtual Channel Multiplexing
VirtualChannelHandler -> MasterChannelHandler : enqueueTransferFrame(virtualChannelFrame)
note right
Transfers frames from a single Virtual Channel
to the Master Channel queue.
end note

' Master Channel Frame Handling
MasterChannelHandler -> MasterChannelHandler : processMasterChannelFrame(virtualChannelFrame)
note right
Processes Virtual Channel Frames:
- Adds Master Channel Frame Count to Primary Header.
- Skips optional fields (FSH, OCF).
end note

' Master Channel Multiplexing
MasterChannelHandler -> PhysicalChannelHandler : enqueueForTransmission(masterChannelFrame)
note right
Queues frames from a single Master Channel
for transmission. No multiplexing needed
as there is only one Master Channel in use.
end note

' Finalization and Transmission
PhysicalChannelHandler -> PhysicalChannelHandler : finalizeTransferFrame(masterChannelFrame)
note right
Finalizes frame:
- Calculates CRC and inserts it into the Frame Error Control Field (FECF).
- Marks idle frames if no data is available.
end note

PhysicalChannelHandler -> PhysicalChannelHandler : transmitTransferFrame(finalizedFrame)
note right
Sends completed frames over the Physical Channel
at a constant rate to meet protocol timing.
end note
@enduml
#+END_SRC

#+RESULTS:
[[file:.org_out/ccsds_tm_datalink_sequence.svg]]

** Communication Topology Comparison
*** Legacy
[[file:.org_out/LegacyDeploymentLink.png]]
*** New
[[file:.org_out/NewDeploymentLink.png]]
** Implementation Strategy
*** Data Categorization and Protocol Mapping
| FPrime Data Type | Characteristics         | CCSDS Protocol | Service | Virtual Channel Usage        |
|------------------+-------------------------+----------------+---------+------------------------------|
| Telemetry        | Continuous, Rate-based  | TM Space Link  | VCAS    | Organized by rate groups     |
| Commands         | Discrete, Requires ACK  | TC Space Link  | VCAS    | Dedicated command channel    |
| Events           | Discrete, One-way       | TC Space Link  | VCAS    | Shared notification channel  |
| Parameters       | Discrete, Configuration | TC Space Link  | VCAS    | Shared configuration channel |

*** Communication Pipeline Overview
**** Downlink Path (Space to Ground)
- Telemetry frames organized by rate groups into virtual channels
- Events and parameter updates multiplexed into respective TC virtual channels
- Uni-directional RF link carries all downlink traffic
- UDP link (during testing) provides same structure with added ACK capability

**** Uplink Path (Ground to Space, UDP Only)
- Commands transmitted via dedicated TC virtual channel
- Command acknowledgment mechanism implemented for UDP testing
- Retransmission logic handles lost commands during UDP communication

*** Protocol Details
NOTE see managed parameters, note that by leveraging the mux scheme into function parameters we can implicitly mux and wrap all channels into one frame
**** TM Space Link Implementation
- VCAS service provides dedicated bandwidth per rate group
- Frame size optimization based on rate group proportions
- Sequence tracking at frame level

***** Synchronization and channel coding
In order to properly configure the various channels we consult the Synchronization and channel coding mechanisms described in CCSDS 131.0-B-5

[[file:.org_out/tm_sync_and_channel_coding_layered_model.png]]

**** TC Space Link Implementation
- Virtual channels segregate different data types
- Command channel includes verification and retransmission logic
- Events and parameters share notification/configuration channels
- Frame sequence maintained at protocol level

*** Key Design Decisions
- VCAS chosen for simplified bandwidth allocation
- Virtual channel organization prioritizes data type separation
- Frame-level sequence tracking sufficient for requirements
- UDP testing preserves operational protocol structure

